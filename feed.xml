<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://anonymous3141.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://anonymous3141.github.io//" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-09T10:38:01+00:00</updated><id>https://anonymous3141.github.io//feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://anonymous3141.github.io//blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://anonymous3141.github.io//blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://anonymous3141.github.io//blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024 We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we‚Äôre introducing Gemini 1.5 Flash: a model that‚Äôs lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We‚Äôre also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5‚Äôs 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It‚Äôs optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it‚Äôs a lighter weight model than 1.5 Pro, it‚Äôs highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it‚Äôs been trained by 1.5 Pro through a process called ‚Äúdistillation,‚Äù where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash‚Äôs availability and pricing.Over the last few months, we‚Äôve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we‚Äôve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We‚Äôve improved control over the model‚Äôs responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we‚Äôve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we‚Äôre now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do ‚Äî not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we‚Äôre also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We‚Äôre announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we‚Äôve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind‚Äôs mission to build AI responsibly to benefit humanity, we‚Äôve always wanted to develop universal AI agents that can be helpful in everyday life. That‚Äôs why today, we‚Äôre sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do ‚Äî and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we‚Äôve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we‚Äôve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we‚Äôve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they‚Äôre being used in, and respond quickly, in conversation.With technology like this, it‚Äôs easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We‚Äôve made incredible progress so far with our family of Gemini models, and we‚Äôre always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we‚Äôre able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google‚Äôs privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let‚Äôs stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We‚Äôre sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://anonymous3141.github.io//blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://anonymous3141.github.io//blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://anonymous3141.github.io//blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[<h3>External Posts on Your al-folio¬†Blog</h3> <p>If you prefer publishing blog posts on medium.com or other external sources, starting version v0.5.0, <a href="https://github.com/alshedivat/al-folio">al-folio</a> lets you to display your external posts in the blog feed of your website!¬†üéâüéâ</p> <p>Configuring external sources of super simple. After upgrading to v0.5.0, just add the following section to your _config.yml:</p> <pre>external_sources:<br />  - name: medium.com  # name of the source (arbitrary string)<br />    rss_url: <a href="https://medium.com/@al-folio/feed">https://medium.com/@&lt;your-medium-username&gt;/feed</a></pre> <p>The example above adds your medium.com blog post feed as an external source. But you can add arbitrary RSS feeds as¬†sources.</p> <p>Any questions or suggestions? üëâ Start <a href="https://github.com/alshedivat/al-folio/discussions">a discussion on¬†GitHub</a>!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b60a1d241a0a" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">On Tree graphs</title><link href="https://anonymous3141.github.io//blog/2020/Tree-Graphs/" rel="alternate" type="text/html" title="On Tree graphs"/><published>2020-12-21T00:00:00+00:00</published><updated>2020-12-21T00:00:00+00:00</updated><id>https://anonymous3141.github.io//blog/2020/Tree-Graphs</id><content type="html" xml:base="https://anonymous3141.github.io//blog/2020/Tree-Graphs/"><![CDATA[<h1 id="algorithms-regarding-to-trees">Algorithms regarding to Trees</h1> <p>Trees is one of the greatest areas in graph theory covered in informatics contests, and is increasing in popularity rapidly. In this blog we cover some tree algorithms.</p> <h3 id="notes">Notes</h3> <ul> <li>Let $\mathcal{T}$ denote a Tree</li> <li>Familiarity is assumed with fundamental algorithms of trees like LCA and important principles like Euler tour and diameter. <h2 id="two-lemmas-on-the-diameter">Two Lemmas on the diameter</h2> <ol> <li>If node sets $X$ and $Y$ are diameters of a tree, then $X\cap Y\neq \emptyset$.</li> <li>For any node $v\in \mathcal{T}$, the furthest node $u$ from $v$ is the endpoint of at least 1 diameter path.</li> </ol> </li> </ul> <p>We Prove these lemmas Here.</p> <p><strong>Proof (1):</strong></p> <p>We proceed constructively. Consider a midpoint of one of the diameters X (i.e a middle node in the path). If this midpoint is not also a midpoint of the other diameter then we can form a longer path by connecting one of the halves of X to a part of Y. We leave the details to the reader. This midpoint is called the <em>centre</em>.</p> <p><strong>Proof (2):</strong> Suppose $A,B$ are the endpoint of a diameter and WLOG $d(v,A)\leq d(v,B)\leq d(v,u)$. Rooting the tree at $v$, consider $C$ the lowest common ancestor LCA of $B$ and $u$. Then $d(C,B)\leq d(c,u)$ by assumption that $u$ is the furtherest node. If the path $UV$ is disjoint from $AB$ then $d(A,u) = d(A,c) + d(c,u) \geq d(A,B)$ so $u$ is also the endpoint of a diameter. If the paths share an edge the logic also falls out similarly.</p> <h3 id="applications-of-the-two-lemmas">Applications of the two lemmas.</h3> <p>Arguably, Lemma 2 is the more useful of the two. Lets consider two problems.</p> <p><strong>Problem 1</strong> Module task: Given hidden tree of N nodes, you can query distance between two points. Find the length of the diameter in 2N queries.</p> <p><strong>Answer:</strong> Trivial application of lemma 2.</p> <p><strong>Problem 2</strong> Given unweighted tree construct permutation of nodes $v_1 ‚Ä¶ v_N$ such that $d(v_i,v_{i+1})\geq d(v_{i+1}, v_{i+2})$.</p> <p><strong>Answer:</strong> Lets find a diameter of a tree and let its endpoint be $x$. We construct the sequence by repeatedly finding the furtherest node from $x$. Observe that at each iteration of the algorithm the diameter of the tree is nonincreasing. Further, we prove inductively that at each iteration the node we currently occupy is an endpoint of at least 1 diameter on the tree. Lets suppose that from $x$ we go to $y$. Then $xy$ is a diameter path clearly by definition. Now from $y$ we can at least guarantee a diameter of $d(x,y)-1$ by going from $y$ to the second node in the path from $x$ to $y$. If there still exist a path of length $d(x,y)$ then it must share an node with the path $xy$ by Lemma 1. As such when the tree is rerooted at $y$ the endpoints of the previous diameter become accessible to $y$ and we will jump to there instead.</p> <p><strong>Problems to ponder:</strong></p> <ul> <li>APIO 2020 Fun tour</li> <li>IOI 2015 Towns</li> </ul> <h2 id="centres-of-the-tree">Centres of the Tree</h2> <p>There are several important points in every tree</p> <p><strong>Centroid:</strong> This node minimises the sum of distances to every other node in the tree, and also has many other useful properties</p> <p><strong>Centre of tree:</strong> Minimises the depth of the tree if rooted at it. Found by taking the midpoint of the diameter. A tree has one or two centres.</p> <p>We will not in depth cover the Centre, but focus on Centroid.</p> <p><strong>Property of Centroid:</strong> In addition to minimising the sum of distances, the centroid splits the tree into subtrees, none of which have more nodes than half the side of the tree.</p> <p><strong>Proof:</strong> Suppose otherwise, then if we shift the centroid towards subtree with the majority of the nodes then we reduce distance sum. We can use this of thus construct the centroid by starting at a leaf and repeatedly walking in a direction that minimises distance sum.</p> <p><strong>Applications:</strong> The main application for centroids is <em>centroid decomposition</em>. Effectively, we find the centroid, remove it and recursively apply the process onto the resulting subtrees. It is equivalent to divide and conquer on tree, and facilitates many effective algorithms for interactive and data structure problems.</p> <p><strong>Example:</strong> Maintain weighted tree with edge updates, after each update find diameter length.</p> <p><strong>Solution:</strong> Consider the set of trees $\mathcal{S}$ produced by the centroid decomposition (i.e the original tree, the trees produced by the deletion of the first centroid, the second, etc). The total size of these trees is $O(NlogN)$ by the divide and conquer procedure. In this procedure, the intact diameter path must pass through the centroid of at least one of these trees. Thus by rooting each of the trees in $\mathcal{S}$ at the centroid of each tree, we only need to consider the paths passing through the root of each centroid tree and take the maximum overall. This can be maintained with lazy proprogation segment tree. When updates happen, we update the centroid trees of the $O(logN)$ centroid trees containing that edge.</p> <p>This demonstrates the key idea of centroid decomposition, that every path passes through a centroid in some centroid tree. Centroid decomposition has other applications too, such as:</p> <ul> <li>Binary search on Tree</li> <li>Setting up a tree for pairing style problems where a majority is undesirable</li> </ul> <p><strong>Problems to ponder</strong></p> <ul> <li>Dynamic Diameter (CEOI20)</li> <li>JOI2020 Capital City</li> </ul> <h2 id="virtual-tree">Virtual Tree</h2> <p>The whole concept of virtual tree centres around the following fact:</p> <p><strong>Fact:</strong> Given a tree $\mathcal{T}$ and $K$ paths on this tree, the union of these paths‚Äô edges results in a subgraph with $O(K)$ nodes having a degree other than 2.</p> <p><strong>Proof of fact:</strong> Let Proceeding inductively, lets add the paths one by one to the subgraph, under the assumption that the subgraph takes the shape of a tree (if the end subgraph is a tree, then such a sequence must exist). Each path crosses the subgraph at most twice (otherwise there would be a cycle) by entering then leaving the subgraph. Thus all we do by adding the path is adding two branches to the tree. We leave the reader to formalise this into a proof.</p> <p><strong>Applications:</strong> Given problems that involve paths on a tree, virtual tree lets us consider subsets of these paths in isolation in good time. Let us consider the following problem:</p> <p><strong>Problem:</strong> Given tree of $N$ nodes, answer $Q$ queries of the forms;</p> <ul> <li>Given a set of paths on this tree, deduce the diameter of the subgraph resulting from the union of these paths.</li> <li>Given a set of points on this tree, deduce the furtherest pair of points apart</li> </ul> <p>The sum of the number of paths and points over all queries is $K$.</p> <p><strong>Solution:</strong> To Achieve $O((N+K)logN)$ complexity the problem reduces down really to building the virtual trees (forest) per query, compressing sequences of degree two ‚Äúimportant‚Äù (not degree 2) nodes on the trees down to weighted paths, then finally running the standard diameter algorithm on the tree. Thus the problem boils down to constructing virtual trees efficiently. Now we discuss the construction of the virtual forest henceforth in 2 approaches.</p> <p><strong>Approach 1: for set of points</strong></p> <p>This elegantly applies LCA. Rooting the tree at 1, we note that any node which does not have degree 2 is the LCA of two of the nodes. We consider the following claim..<br/> <em>Lemma:</em> Consider the nodes $v_1 ‚Ä¶ v_n$ in euler ordering (taking first occurrence of each label). Then for any $(x,y)$ there exist $z$ that $LCA(v_x,v_y)=LCA(v_z,v_{z+1})$.</p> <p><em>Proof:</em> Map the tree into an array of integers, where the index key is the position on euler ordering and index value is the depth of the node in that position. Then $v_l=LCA(v_x,v_y)$ corresponds to the node that is the result of $rangeminquery(pos(v_x), pos(v_y))$. Consider the nodes immediately to left and right of $v_l$ on the euler ordering. Then it follows that the LCA of these nodes is also $v_l$ by property of RMQ, as these nodes are necessarily enclosed by the interval $(pos(v_x), pos(v_y))$ as required.</p> <p>Thus, we can effortlessly find the important nodes of the virtual tree, and it remains to link them up. We can do this by sweeping nodes by depth from high to low. Maintain a map keyed by euler order. When a node is encountered delete the nodes in the map contained by the interval it covers and set them as its children, being conscious of the edge lengths (take difference in depth). Then insert the node itself into the map.</p> <p><strong>Approach 2: for set of paths</strong></p> <p>If we merely build the virtual tree for the set of path endpoints, then it must be that the actual virtual forest is a subset of the edges of this virtual tree. We simply must mark the edges which are relevant within this virtual tree. Thus we have the problem of being given the virtual tree of n nodes and calculating the union of paths on the tree in $\tilde{O}(n)$. Lets assume all paths go from ancestor (head) to descendant (tail) (otherwise split each path in two at the LCA). Euler traverse the tree, and when the head of a path is encountered insert the tail to a set that is keyed by euler tour. To decide whether an edge is on we merely have to check if there is an active node within the subtree of the edge. Now each path‚Äôs tail is only inserted and deleted once, so complexity is $O(nlogn)$.</p> <p><em>The euler tour sweep</em></p> <p>Lastly, it should we mentioned that the virtual tree is a good tool in module tasks to build up a tree as more information is obtained.</p> <h2 id="greedy-algorithms-and-small-merge">Greedy algorithms and small merge</h2> <p>Tree problems often involve greedy solutions, which are done through exploiting extremal structures in the tree such as the leaf. We discuss the following points:</p> <ul> <li>Solving the problem on subtrees</li> <li>Decrease and conquer (forced moves)</li> <li>Shaving off leaves</li> <li>The benefits of having a combinatorial upper/lower bound on the answer (Thanks Ray Li for teaching me this)</li> </ul> <h3 id="example-1-edge-matching">Example 1: Edge matching</h3> <p>Suppose that in a graph $G=(V,E)$ we want to find a max matching among edges where edges $u,v$ can be matched if they share a common endpoint (are incident).</p> <p>We do this by constructing the edge tree through a dfs on the edges of the graph. In the resulting tree we observe two results:</p> <ul> <li>Every edge in the edge-dfs tree (henceforth edge-tree) corresponds to an edge in the original graph</li> <li>If two edges are incident in the edge-tree they are incident also in the original graph</li> </ul> <p>We will now solve the edge-matching problem on this graph, and show that solving the problem on the tree.</p> <p>Rooting arbitrarily, consider the deepest leaf $v$and its parent $p$. Suppose $p$ has no other children. Then we match the edges $(v,p)$ and $(p, par(p))$. Otherwise, we match $(v,p)$ with $(u,p)$ where $u$ is a sibling of $v$. This strategy, at every iteration, deletes two edges from the tree while maintaining the connectivity of the tree‚Äôs remaining edges. Thus with this strategy we can achieve $\lfloor \frac{E}{2} \rfloor$ matchings total, the theoretic maximum. Thus, as we can achieve the maximum by considering the tree structure, we can map this to a solution in the original graph.</p> <p>This example shows us, that a naive upper bound, combined with consideration of subtrees, can reap rewards.</p> <h3 id="resolving-subtrees">Resolving subtrees</h3> <p>Consider the problem <a href="https://acio-olympiad.github.io/2020/snap.pdf">Snap Tokens</a> from ACIO 2021 Contest 2. While the actual problem asks for solutions on vortex graphs, we solve the problems on trees first.</p> <p>Rooting the tree arbitrarily is a good start, and we should think about what happens in a subtree. We make a few observations:</p> <ul> <li>It should be obvious that an edge is traversed at most once, otherwise the two movements of tokens cancel out</li> <li>It should also be obvious that moving token $a$ to annihilate token $b$ is the same as moving $b$ to $a$</li> </ul> <p>With this in mind, lets consider what happens in the subtree of $v$:</p> <ul> <li>If there is no tokens, we are done</li> <li>If there is one token, we are forced to move it upwards to the parent of $v$ (as moving tokens downwards to meet it is the same as moving it upwards to meet the token, so we should take care of the subtree)</li> <li>If we have multiple tokens in our subtree it gets interesting. We recursively solve the problem on the subtrees first, then some tokens would get moved to the node $v$. These cancel out, leaving nothing or at most 1 spare token behind. In the final case, we have to move this token upwards.</li> </ul> <p>This gives us an immediate solution to the tree case, and by considering the vortex as trees hanging off a cycle, it turns out the problem is basically solved (the case of cycle left to reader).</p> <p>However, a interesting extension to the problem is where there are updates of the form: <strong>Move a token from node $u$ to $v$</strong> (we will concern ourselves with the tree case, the cycle is more tedious, but is largely uninteresting)</p> <p>Now, we need a more elegant form of counting the number of needed moves. We apply some combinatorial thinking, and ask: Under what conditions do we need to move a token from $v$ to its parent (it is almost as if we try to lower bound the answer)?</p> <p>We leave the reader to consider this. Note that even with this more elegant condition, HLD is needed to solve the problem.</p> <p>Here, combinatorial thinking and breaking the problem into subtrees has paid dividends.</p> <h3 id="job-scheduling-ioi19-practice-contest">Job Scheduling (IOI19 practice contest)</h3> <p>This is a fantastic problem that I won‚Äôt spoil. But thinking about extreme ‚Äúforced moves‚Äù within the decision making on the tree is a good course of action. This is also a valid approach for greedy problems in general.</p> <h2 id="advanced-dp-on-tree">Advanced DP on tree</h2> <p>DP on tree involves solving problems on subtrees of the original tree, then merging these answers to produce the original solution. However, there are many tools to accelerate these dps.</p> <h3 id="optimising-on2-to-onlogn">Optimising $O(N^2)$ to $O(NlogN)$</h3> <p>Suppose that a tree dp takes the form of $dp[\text{subtree v}][\text{some attribute j, say time}]$, but the transitions are relatively simple functions. Then we can use a data structure, like a segment tree or set, to maintain the second dimension $j$ for a subtree. We can use small merge to accelerate state transitions. Please see the section in ‚ÄúSegment Trees‚Äù on mergeable segment trees for an example.</p> <h3 id="sibling-dp">Sibling dp</h3> <p>In short, an algorithm that appears to be $O(N^3)$ is actually $O(N^2)$. It is best explained with an example (courtesy of I_am_sb, from a Chinese Provincial Selection Exam)</p> <p><strong>The problem: Monochrome Tree</strong> You are given a weighted tree with $N\leq 2000$ nodes. You are also given an integer $0\leq K\leq N$. You are to choose $K$ nodes from this tree and colour them black, with the rest being coloured white. The score of the tree, which you must maximise, is the sum: \(S(\mathcal{T})=\sum_{u\ black} \sum_{v\ white} dist(u,v)\)</p> <p>Output the maximium score. <strong>The solution:</strong> Rooting arbitarily and sing the most obvious dp state, we have $dp[i][j]=max$, where $i$ is the subtree, and $j$ is the number of black nodes assigned to the subtree. We apply our combinatorical thinking in constructinng our recursion, and think about the contribution of an edge to the final score.</p> <p>Deleting a certain edge $(u,v)$ where $u$ is the parent of $v$, will say split the tree into two connected components with $x$ and $N-x$ nodes where $x$ is the size of the subtree at $v$. If we allot $b$ black nodes to the subtree of $v$ then $f(v,b)=b(N-x+b-K) + (K-b)(x-b)$ different black-white node pair paths will cross the edge $(u,v)$ , so the contribution of the edge $(u,v)$ is its weight multiplied by $f(v,b)$.</p> <p>Let $slv(i)$ be a function that finds $dp[i][j]$ for all $0\leq j \leq size(i)$, where size denotes subtree size. Its psuedocode might look something like this, where we recursively solve the subtrees then do a knapsack dp to find the best allocation of black nodes to the subtrees.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>void slv(v)
	Let c = num_children(v)
	Let dp2[size(v)][2] := new array
	for each child i = 1 ... c: 
		Let s := sum of subtree sizes 1 ... i-1
		slv(i)
		for k = 0 ... size(i) // how many black nodes for i
			for j = 0 ... s:
				dp2[k+j][i%2] = max(dp2[k+j][i%2], dp2[j][(i+1)%2]+dp[i][k] + f(i,k) * W(v,i))
	dp[v][i] := dp2[i][c%2] FOR ALL i
</code></pre></div></div> <p>On the surface the complexity seems terrible. But let us be a little more dilligent in our analysis.</p> <p>Consider the following function, which is basically the same:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>void disp(v):
	for each child i = 1 ... c:
		disp(v)
		for each node a in subtree of i:
			for each node b in subtrees 1 ... i-1:
				print(a,b)
</code></pre></div></div> <p>Note that the complexity of the two functions disp and slv are same. Note further, that what disp does, is print every pair of nodes once, with disp(lca(a,b)) printing the pair (a,b). Thus we can also conclude that that slv() runs in $O(N^2)$, which solves our problem.</p> <p>This is one of the more magical tree dps that can be used.</p> <p><em>Note:</em> By adding zero weight edges and nodes ignored in subtree size calculations, the implementation can be simplified by turning the tree into a binary tree. This is called the left-child right sibling idea, and is useful in these cases.</p> <h2 id="hld-and-other-data-structures-on-trees">HLD and other data structures on Trees</h2> <h3 id="preorder-sweep-and-euler-tour">Preorder Sweep and Euler Tour</h3> <p>Please see the page on segment trees.</p> <h3 id="hld">HLD</h3> <p>Its useful and many other people can explain it better than I do. See cp-algorithms for a good explaination.</p> <h2 id="general-problems">General Problems</h2> <ul> <li>ACIO 2020 Open Contest Black Panthers</li> <li>ACIO 2020 Open Contest Vibe Check</li> <li>ACIO 2020 Contest 2 Tokens</li> <li>CEOI 2020 Spring cleaning</li> <li>CEOI 2019 Magic Tree</li> <li>Baltic OI 2015 Network</li> <li>Baltic OI 2020 Day 2 Village</li> <li>IOI 2019 Practice Contest Job Scheduling</li> <li>IOI 2018 Highway Tolls</li> <li>IOI 2013 Dream</li> <li>IOI 2011 Race</li> <li>IOI 2005 Riv</li> <li>COI18 Paprike</li> <li>FARIO 2011 Virus</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[On Tree graphs]]></summary></entry></feed>